# vim: ft=python

configfile: 'config/hpv_config.yaml'
workdir: os.environ['PWD']
shell.executable('bash')

localrules: all_qc

rule all_qc:
    input: qc_targets

rule pretrim_qc:
    input: 'bams/{sampleID}.bam'
    output: 'pretrim_qc/{sampleID}_fastqc.zip'
    threads: 4
    run:
        shell('fastqc {input} -t {threads} --outdir=pretrim_qc')

rule posttrim_qc:
    input: 'mapq_filter/{sampleID}.filtered.bam'
    output: 'posttrim_qc/{sampleID}.filtered_fastqc.zip'
    threads: 4
    run:
        shell('fastqc {input} -t {threads} --outdir=posttrim_qc')

rule fastqc_report:
    input:
        expand('pretrim_qc/{sampleID}_fastqc.zip', sampleID=sampleIDs),
        expand('posttrim_qc/{sampleID}.filtered_fastqc.zip', sampleID=sampleIDs)
    output: 'multiqc/fastqc_report_data/multiqc_general_stats.txt'
    run:
        shell('multiqc -f -d pretrim_qc posttrim_qc -o multiqc -n fastqc_report')


# TODO - someday make a file that looks for samples with low quality and flags them
rule filtered_count:
    input: rules.fastqc_report.output
    output: report('reports/filtered_read_count.tsv')
    run:
        df = pandas.read_table(input[0], sep='\t')
        df['sampleID'] = df['Sample'].apply(lambda x: x.split(' | ')[1].split('.')[0])

        pre = df[df['Sample'].str.contains('pretrim')][['sampleID', 'FastQC_mqc-generalstats-fastqc-total_sequences']].copy()
        post = df[df['Sample'].str.contains('posttrim')][['sampleID', 'FastQC_mqc-generalstats-fastqc-total_sequences']].copy()

        dd = pre.merge(post, on='sampleID', suffixes=('_pre', '_post'))
        dd['lowq_reads'] = dd['FastQC_mqc-generalstats-fastqc-total_sequences_pre'].astype(float) - dd['FastQC_mqc-generalstats-fastqc-total_sequences_post'].astype(float)
        dd['lowq_perc'] = 100 - (dd['FastQC_mqc-generalstats-fastqc-total_sequences_post'].astype(float) / dd['FastQC_mqc-generalstats-fastqc-total_sequences_pre'].astype(float) * 100)

        #shell('mkdir -p reports')  # at some point this directory wasn't created...?
        dd.to_csv('reports/filtered_read_count.tsv', sep='\t', index=False)


# Check if there are any blanks with unexpectedly high mapped reads
rule qc_blanks:
    input: expand('idxstats/{blank}.idxstats.txt', blank=blanks)
    output: 'flags/blank_qc.txt'
    params: cov = config['qc_min_reads']
    run:
        if len(input) > 0:
            dfs = []
            for fname in input:
                temp = pandas.read_csv(fname, sep='\t', names=['chr', 'len', 'count', '0'])
                temp = temp[temp['chr'].str.startswith('HPV')]
                temp = temp[temp['count'] > params.cov]
                temp['sampleID'] = fname.split('/')[-1].split('.')[0]
                dfs.append(temp)

            df = pandas.concat(dfs)
            df.to_csv(output[0], sep='\t', index=False)
        else:
            shell('echo "" > {output}')

