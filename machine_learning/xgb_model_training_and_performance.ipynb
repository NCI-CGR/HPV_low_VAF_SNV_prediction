{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e948a578",
   "metadata": {},
   "source": [
    "# Notebook for HPV Triplicate Study"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68dd48ac",
   "metadata": {},
   "source": [
    "This notebook includes the steps involving the training and testing of <b> extreme gradient boosting (XGBoost) </b> machine learning models for predicting true low/intermediate-VAF <b> intrahost single nucleotide variants (iSNVs) </b> in HPV. The data files used for model training and testing in this notebook were generated using an in-house variant calling pipeline and a set of in-house scripts that processed the VCF files and parsed the variants, their replicate frequency and all the 31 features into a csv file. The notebook is indended to serve as reference for readers to understand how XGBoost model training and testing was performed in our study and more importantly, for reproducibility of the study results.\n",
    "\n",
    "We have included the training and testing steps for the 3 scenarios described in our study: <p>\n",
    "> <p> <b> 1. Machine learning with VAF filters (FM models) </b>\n",
    "> <p> <b> 2. Macine learning with VCFgenie without any low-VAF filters (VM models) </b> <p>\n",
    "> <p> <b> 3. Machine learning with VCFgenie with low-VAF filters (FVM models) </b> <p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e0fd437",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6529834e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import random\n",
    "from scipy import stats\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "from itertools import product\n",
    "warnings.filterwarnings(\"ignore\") # Will suppress any unnecessary warnings\n",
    "\n",
    "# ML libraries\n",
    "import numpy as np\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc, classification_report\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, matthews_corrcoef\n",
    "from sklearn.metrics import mean_squared_error, cohen_kappa_score, make_scorer\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, average_precision_score, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c27b4b",
   "metadata": {},
   "source": [
    "## Define some custom functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c6bae62",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Plot settings\n",
    "sns.set_style('ticks')\n",
    "\n",
    "def remove_low_coverage_samples(df_snv_w_cov, min_cov_cutoff, coverage_column):\n",
    "    \"\"\"\n",
    "    Remove iSNVs that do not meet quality control criteria: FDP cutoff >= 100 and FAO > 0\n",
    "        df_snv_w_cov: The dataframe with all SNVs and their features\n",
    "        min_cov_cutoff: The minimum value for coverage\n",
    "        coverage_column: The coverage column (FDP or FAO for Ion Torrent data)\n",
    "    \"\"\"\n",
    "    df_snv_high_cov = df_snv_w_cov.copy()\n",
    "    df_snv_high_cov = df_snv_high_cov.loc[df_snv_high_cov[coverage_column] >= min_cov_cutoff]\n",
    "    df_snv_high_cov.reset_index(drop=True, inplace=True)\n",
    "    return df_snv_high_cov\n",
    "    \n",
    "def create_balanced_datasets(X,y, seed_value=10, t_size=0.3, true_label=1, false_label=0):\n",
    "    \"\"\"\n",
    "    Create balanced datasets for training. The test data will remain imbalanced.\n",
    "        seed_value : The seed for random state selection\n",
    "        t_size : Size of the test data. Note that this is 30% of the entire data \n",
    "                (true label + false label), not 30% of each label. You may notice that \n",
    "                the test data for the individual labels (true label or false label) are not exactly \n",
    "                30% of the entire data. \n",
    "        true_label : The numeric label for the true variants\n",
    "        false_label: The numeric label for the false variants\n",
    "    \"\"\"\n",
    "    train_samples = {} # Dictionary in which we will store the training samples\n",
    "    train_index_list = [] # Will keep track of the indices of the sampled rows in the training data.\n",
    "                          # Depending on the value set for alpha, the number of unique indices\n",
    "                          # should equal to the size of the training data.\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=t_size, random_state=seed_value)\n",
    "#     print (X_train)\n",
    "    X_train.reset_index(inplace=True, drop=True)\n",
    "    \n",
    "    # If the training data is not balanced, then undersample the over-represented class\n",
    "    # and create multiple training datasets.\n",
    "    num_true = y_train.count(true_label) # Number of true labels\n",
    "    num_false = y_train.count(false_label) # Number of false labels\n",
    "    \n",
    "    # Identify the over-represented class \n",
    "    if num_true > num_false:\n",
    "        over_rep_class = true_label\n",
    "        over_rep_count = num_true\n",
    "        under_rep_class = false_label\n",
    "        under_rep_count = num_false\n",
    "    elif num_false > num_true:\n",
    "        over_rep_class = false_label\n",
    "        over_rep_count = num_false\n",
    "        under_rep_class = true_label\n",
    "        under_rep_count = num_true\n",
    "    else:\n",
    "        # Both classes are balanced\n",
    "        train_samples['1'] = {}\n",
    "        train_samples['1']['X_train'] = X_train\n",
    "        train_samples['1']['y_train'] = y_train\n",
    "        return train_samples, X_test, y_test, train_index_list\n",
    "    \n",
    "    # # Commenting out this debug info statement for now. Uncomment when needed.\n",
    "    # print (\"\\tTrain-test split resulted in imbalanced training data\", flush=True)\n",
    "    # print (f\"\\tOver-represented class = {over_rep_class}, count = {over_rep_count}\", flush=True)\n",
    "    # print (f\"\\tUnder-represented class = {under_rep_class}, count = {under_rep_count}\", flush=True)\n",
    "    # print (\"\\tWill proceed by creating balanced training data.\", flush=True)\n",
    "    \n",
    "    alpha = 5 # A sampling weight constant that determines the number of times\n",
    "            # the over-represented class will be sampled.\n",
    "    num_sample_iter = int(round(over_rep_count/under_rep_count)*alpha)\n",
    "    sample_size = under_rep_count\n",
    "    seed_list = list(range(1,num_sample_iter+1)) # The seeds we will use for each iteration of sampling.\n",
    "                                                 # This is to make the results reproducible.\n",
    "    # Identify the indices of the over-represented and under-represented class\n",
    "    # and get the respective data in X_train.\n",
    "    over_rep_indices = list(np.where(np.array(y_train) == over_rep_class)[0])\n",
    "    X_train_over_rep = X_train.iloc[over_rep_indices]\n",
    "    under_rep_indices = list(np.where(np.array(y_train) == under_rep_class)[0])\n",
    "    X_train_under_rep = X_train.iloc[under_rep_indices]\n",
    "   \n",
    "    # Perform sampling\n",
    "    for seed_i in seed_list:\n",
    "#         print (f\"Sampling iteration {seed_i}...\", flush=True, end='')\n",
    "#         print (sample_size)\n",
    "#         print (len(X_train_over_rep))\n",
    "#         print (len(X_train_under_rep))\n",
    "        X_train_sample_i_over_rep= X_train_over_rep.sample(n=sample_size, replace=False, random_state=seed_i)\n",
    "        y_train_sample_i_over_rep = [over_rep_class] * sample_size\n",
    "        # Consolidate the training feature data for the under represented class\n",
    "        # and over-represented class into a single data frame\n",
    "        X_train_sample_i = X_train_sample_i_over_rep.append(X_train_under_rep)\n",
    "        \n",
    "        ind_i_list = X_train_sample_i.index.tolist()\n",
    "    #     print (ind_i_list)\n",
    "    #     break\n",
    "        if len(train_index_list) == 0:\n",
    "            train_index_list = ind_i_list\n",
    "        else:    \n",
    "            train_index_list.extend(ind_i_list)\n",
    "        \n",
    "        # Turn off reset index for de-bugging\n",
    "        X_train_sample_i.reset_index(inplace=True, drop=True)\n",
    "        # Consolidate the training labels for the under represented\n",
    "        # and over represented classes\n",
    "        y_train_sample_i = y_train_sample_i_over_rep  + [under_rep_class] * sample_size\n",
    "        \n",
    "        # Shuffle the rows. Otherwise the Top N rows will be over-rep class and \n",
    "        # bottom N rows will be under-rep class.\n",
    "        X_train_sample_i_shuffled = X_train_sample_i.sample(frac=1, random_state=seed_i)\n",
    "        shuffled_indices = X_train_sample_i_shuffled.index.to_list()\n",
    "        #\n",
    "        y_train_sample_i_shuffled = [y_train_sample_i[ind_i] for ind_i in shuffled_indices]\n",
    "        train_samples[seed_i] = {}\n",
    "        train_samples[seed_i]['X_train'] = X_train_sample_i_shuffled\n",
    "        train_samples[seed_i]['y_train'] = y_train_sample_i_shuffled\n",
    "    return train_samples, X_test, y_test, train_index_list\n",
    " \n",
    "def get_ensemble_prediction(y_scores_all_models):\n",
    "    \"\"\"\n",
    "    For a given testing point, get the median score across all the models.\n",
    "    If the median score is >= 0.5, then label 1 else label 0. \n",
    "    \"\"\"\n",
    "    median_scores = list(y_scores_all_models.median(axis=1))\n",
    "    median_labels = list(map(lambda x: 0 if (round(x,2) < 0.5) else 1, median_scores))\n",
    "    return median_labels\n",
    "\n",
    "\n",
    "def get_ensemble_prediction_scores(y_scores_all_models):\n",
    "    \"\"\"\n",
    "    Return the median scores across all the models for a given test \n",
    "    data point.\n",
    "    \"\"\"\n",
    "    median_scores = list(y_scores_all_models.median(axis=1))\n",
    "    median_scores = [round(score_i,2) for score_i in median_scores]\n",
    "    return median_scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87eed974",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Performance without VCFgenie and with a lower and upper bound - <b> <font color='green'> FM models </b> </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2838f0c9",
   "metadata": {},
   "source": [
    "### Define input and output files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d896b772",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create output directory\n",
    "outdir = '../results/'\n",
    "Path(outdir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "# The input vcf .csv file\n",
    "snv_sbs_file = '../data/SNV_data_wo_vcf_genie.csv'\n",
    "\n",
    "# The output file that will include the performance metrics\n",
    "perf_out_file_xgb = outdir + 'performance_FM.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f301f8f",
   "metadata": {},
   "source": [
    "### Define parameters and conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d7fda4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "af_lower = [0.01,0.02,0.05,0.1]\n",
    "af_upper = [0.6,0.5]\n",
    "feature_cat = ['Moderate', 'Strict', 'Exhaustive']\n",
    "\n",
    "# Below, we convert the replicate frequencies into their numerical values.\n",
    "# 1 => Replicate frequency 3/3\n",
    "# 0.67 => Replicate frequency 2/3\n",
    "# 0.33 => Replicate frequency 1/3\n",
    "true_var = [[1],[1,0.67]]\n",
    "false_var = [[0.33], [0.33, 0.67]] # Skip if 0.67 is in both true_var and false_var"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53d2603",
   "metadata": {},
   "source": [
    "### Define feature categories as a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2bd9cb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_cat_dict = {'Moderate': ['FSAF','FSAR','FSRF','FSRR','FWDB','FXX','GQ','MLLD','QUAL','REFB',\n",
    "                'REVB','SAF','SAR','SRF','SRR','SSSB','STB','VARB', '5_PRIME_NUCLEOTIDE_CONTEXT', '3_PRIME_NUCLEOTIDE_CONTEXT'],\n",
    "                'Strict': ['FSAF','FSAR','FSRF','FSRR','FWDB','FXX','MLLD','QUAL','REFB','REVB','SSSB','VARB', \n",
    "                           '5_PRIME_NUCLEOTIDE_CONTEXT', '3_PRIME_NUCLEOTIDE_CONTEXT'],\n",
    "                'Exhaustive': ['AO','DP','FAO','FDP','FRO','FSAF','FSAR','FSRF','FSRR','FWDB',\n",
    "                'FXX','GQ','HRUN','LEN','MLLD','QD','QUAL','RBI','REFB','REVB',\n",
    "                'RO','SAF','SAR','SRF','SRR','SSSB','STB','STBP','VARB', '5_PRIME_NUCLEOTIDE_CONTEXT',\n",
    "                '3_PRIME_NUCLEOTIDE_CONTEXT']\n",
    "                }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86275ee7",
   "metadata": {},
   "source": [
    "### Generate combinations of conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2bc88459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.01, 0.6, 'Moderate', [1], [0.33]), (0.01, 0.6, 'Moderate', [1], [0.33, 0.67]), (0.01, 0.6, 'Moderate', [1, 0.67], [0.33]), (0.01, 0.6, 'Moderate', [1, 0.67], [0.33, 0.67]), (0.01, 0.6, 'Strict', [1], [0.33]), (0.01, 0.6, 'Strict', [1], [0.33, 0.67]), (0.01, 0.6, 'Strict', [1, 0.67], [0.33]), (0.01, 0.6, 'Strict', [1, 0.67], [0.33, 0.67]), (0.01, 0.6, 'Exhaustive', [1], [0.33]), (0.01, 0.6, 'Exhaustive', [1], [0.33, 0.67]), (0.01, 0.6, 'Exhaustive', [1, 0.67], [0.33]), (0.01, 0.6, 'Exhaustive', [1, 0.67], [0.33, 0.67]), (0.01, 0.5, 'Moderate', [1], [0.33]), (0.01, 0.5, 'Moderate', [1], [0.33, 0.67]), (0.01, 0.5, 'Moderate', [1, 0.67], [0.33]), (0.01, 0.5, 'Moderate', [1, 0.67], [0.33, 0.67]), (0.01, 0.5, 'Strict', [1], [0.33]), (0.01, 0.5, 'Strict', [1], [0.33, 0.67]), (0.01, 0.5, 'Strict', [1, 0.67], [0.33]), (0.01, 0.5, 'Strict', [1, 0.67], [0.33, 0.67]), (0.01, 0.5, 'Exhaustive', [1], [0.33]), (0.01, 0.5, 'Exhaustive', [1], [0.33, 0.67]), (0.01, 0.5, 'Exhaustive', [1, 0.67], [0.33]), (0.01, 0.5, 'Exhaustive', [1, 0.67], [0.33, 0.67]), (0.02, 0.6, 'Moderate', [1], [0.33]), (0.02, 0.6, 'Moderate', [1], [0.33, 0.67]), (0.02, 0.6, 'Moderate', [1, 0.67], [0.33]), (0.02, 0.6, 'Moderate', [1, 0.67], [0.33, 0.67]), (0.02, 0.6, 'Strict', [1], [0.33]), (0.02, 0.6, 'Strict', [1], [0.33, 0.67]), (0.02, 0.6, 'Strict', [1, 0.67], [0.33]), (0.02, 0.6, 'Strict', [1, 0.67], [0.33, 0.67]), (0.02, 0.6, 'Exhaustive', [1], [0.33]), (0.02, 0.6, 'Exhaustive', [1], [0.33, 0.67]), (0.02, 0.6, 'Exhaustive', [1, 0.67], [0.33]), (0.02, 0.6, 'Exhaustive', [1, 0.67], [0.33, 0.67]), (0.02, 0.5, 'Moderate', [1], [0.33]), (0.02, 0.5, 'Moderate', [1], [0.33, 0.67]), (0.02, 0.5, 'Moderate', [1, 0.67], [0.33]), (0.02, 0.5, 'Moderate', [1, 0.67], [0.33, 0.67]), (0.02, 0.5, 'Strict', [1], [0.33]), (0.02, 0.5, 'Strict', [1], [0.33, 0.67]), (0.02, 0.5, 'Strict', [1, 0.67], [0.33]), (0.02, 0.5, 'Strict', [1, 0.67], [0.33, 0.67]), (0.02, 0.5, 'Exhaustive', [1], [0.33]), (0.02, 0.5, 'Exhaustive', [1], [0.33, 0.67]), (0.02, 0.5, 'Exhaustive', [1, 0.67], [0.33]), (0.02, 0.5, 'Exhaustive', [1, 0.67], [0.33, 0.67]), (0.05, 0.6, 'Moderate', [1], [0.33]), (0.05, 0.6, 'Moderate', [1], [0.33, 0.67]), (0.05, 0.6, 'Moderate', [1, 0.67], [0.33]), (0.05, 0.6, 'Moderate', [1, 0.67], [0.33, 0.67]), (0.05, 0.6, 'Strict', [1], [0.33]), (0.05, 0.6, 'Strict', [1], [0.33, 0.67]), (0.05, 0.6, 'Strict', [1, 0.67], [0.33]), (0.05, 0.6, 'Strict', [1, 0.67], [0.33, 0.67]), (0.05, 0.6, 'Exhaustive', [1], [0.33]), (0.05, 0.6, 'Exhaustive', [1], [0.33, 0.67]), (0.05, 0.6, 'Exhaustive', [1, 0.67], [0.33]), (0.05, 0.6, 'Exhaustive', [1, 0.67], [0.33, 0.67]), (0.05, 0.5, 'Moderate', [1], [0.33]), (0.05, 0.5, 'Moderate', [1], [0.33, 0.67]), (0.05, 0.5, 'Moderate', [1, 0.67], [0.33]), (0.05, 0.5, 'Moderate', [1, 0.67], [0.33, 0.67]), (0.05, 0.5, 'Strict', [1], [0.33]), (0.05, 0.5, 'Strict', [1], [0.33, 0.67]), (0.05, 0.5, 'Strict', [1, 0.67], [0.33]), (0.05, 0.5, 'Strict', [1, 0.67], [0.33, 0.67]), (0.05, 0.5, 'Exhaustive', [1], [0.33]), (0.05, 0.5, 'Exhaustive', [1], [0.33, 0.67]), (0.05, 0.5, 'Exhaustive', [1, 0.67], [0.33]), (0.05, 0.5, 'Exhaustive', [1, 0.67], [0.33, 0.67]), (0.1, 0.6, 'Moderate', [1], [0.33]), (0.1, 0.6, 'Moderate', [1], [0.33, 0.67]), (0.1, 0.6, 'Moderate', [1, 0.67], [0.33]), (0.1, 0.6, 'Moderate', [1, 0.67], [0.33, 0.67]), (0.1, 0.6, 'Strict', [1], [0.33]), (0.1, 0.6, 'Strict', [1], [0.33, 0.67]), (0.1, 0.6, 'Strict', [1, 0.67], [0.33]), (0.1, 0.6, 'Strict', [1, 0.67], [0.33, 0.67]), (0.1, 0.6, 'Exhaustive', [1], [0.33]), (0.1, 0.6, 'Exhaustive', [1], [0.33, 0.67]), (0.1, 0.6, 'Exhaustive', [1, 0.67], [0.33]), (0.1, 0.6, 'Exhaustive', [1, 0.67], [0.33, 0.67]), (0.1, 0.5, 'Moderate', [1], [0.33]), (0.1, 0.5, 'Moderate', [1], [0.33, 0.67]), (0.1, 0.5, 'Moderate', [1, 0.67], [0.33]), (0.1, 0.5, 'Moderate', [1, 0.67], [0.33, 0.67]), (0.1, 0.5, 'Strict', [1], [0.33]), (0.1, 0.5, 'Strict', [1], [0.33, 0.67]), (0.1, 0.5, 'Strict', [1, 0.67], [0.33]), (0.1, 0.5, 'Strict', [1, 0.67], [0.33, 0.67]), (0.1, 0.5, 'Exhaustive', [1], [0.33]), (0.1, 0.5, 'Exhaustive', [1], [0.33, 0.67]), (0.1, 0.5, 'Exhaustive', [1, 0.67], [0.33]), (0.1, 0.5, 'Exhaustive', [1, 0.67], [0.33, 0.67])]\n",
      "Total combinations = 96\n"
     ]
    }
   ],
   "source": [
    "param_combinations = list(product(af_lower, af_upper, feature_cat, true_var, false_var))\n",
    "print (param_combinations)\n",
    "print (f\"Total combinations = {len(param_combinations)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca110899-79ca-4702-bd77-90f4244bec39",
   "metadata": {},
   "source": [
    "<b><i> Note that for some combinations in the above, the replicate frequency 0.67 (i.e., SNV occurring in 2/3 replicates) is used both for true variants and false variants. Example of such a combination is (0.1, 0.5, 'Exhaustive', [1, 0.67], [0.33, 0.67]). We will exclude such combinations in our analysis, which will result in 72 combinations in total."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38439b40",
   "metadata": {},
   "source": [
    "### Run Xtreme Gradient Boosting iteratively on these conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b19a63ee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running predictions for all parameter/feature combinations with seed 10...Done!\n",
      "Running predictions for all parameter/feature combinations with seed 20...Done!\n",
      "Running predictions for all parameter/feature combinations with seed 3247...Done!\n",
      "Running predictions for all parameter/feature combinations with seed 24...Done!\n",
      "Running predictions for all parameter/feature combinations with seed 4501...Done!\n",
      "Running predictions for all parameter/feature combinations with seed 9879...Done!\n",
      "Running predictions for all parameter/feature combinations with seed 878...Done!\n",
      "Running predictions for all parameter/feature combinations with seed 76...Done!\n",
      "Running predictions for all parameter/feature combinations with seed 187...Done!\n",
      "Running predictions for all parameter/feature combinations with seed 299...Done!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Seed</th>\n",
       "      <th>True_Var_Def</th>\n",
       "      <th>False_Var_Def</th>\n",
       "      <th>VAF_Lower_Limit</th>\n",
       "      <th>VAF_Upper_Limit</th>\n",
       "      <th>Feature_Category</th>\n",
       "      <th>Num_True_Var_Testing</th>\n",
       "      <th>Num_False_Var_Testing</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FN</th>\n",
       "      <th>AUC</th>\n",
       "      <th>MCC</th>\n",
       "      <th>F1_score</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[0.33]</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.6</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>159</td>\n",
       "      <td>1055</td>\n",
       "      <td>123</td>\n",
       "      <td>230</td>\n",
       "      <td>825</td>\n",
       "      <td>36</td>\n",
       "      <td>0.777788</td>\n",
       "      <td>0.413</td>\n",
       "      <td>0.480</td>\n",
       "      <td>0.781</td>\n",
       "      <td>0.219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[0.33, 0.67]</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.6</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>134</td>\n",
       "      <td>1243</td>\n",
       "      <td>104</td>\n",
       "      <td>253</td>\n",
       "      <td>990</td>\n",
       "      <td>30</td>\n",
       "      <td>0.786290</td>\n",
       "      <td>0.387</td>\n",
       "      <td>0.424</td>\n",
       "      <td>0.794</td>\n",
       "      <td>0.206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>[1, 0.67]</td>\n",
       "      <td>[0.33]</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.6</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>287</td>\n",
       "      <td>1090</td>\n",
       "      <td>187</td>\n",
       "      <td>310</td>\n",
       "      <td>780</td>\n",
       "      <td>100</td>\n",
       "      <td>0.683582</td>\n",
       "      <td>0.311</td>\n",
       "      <td>0.477</td>\n",
       "      <td>0.702</td>\n",
       "      <td>0.298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[0.33]</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.6</td>\n",
       "      <td>Strict</td>\n",
       "      <td>159</td>\n",
       "      <td>1055</td>\n",
       "      <td>126</td>\n",
       "      <td>240</td>\n",
       "      <td>815</td>\n",
       "      <td>33</td>\n",
       "      <td>0.782482</td>\n",
       "      <td>0.415</td>\n",
       "      <td>0.480</td>\n",
       "      <td>0.775</td>\n",
       "      <td>0.225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[0.33, 0.67]</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.6</td>\n",
       "      <td>Strict</td>\n",
       "      <td>134</td>\n",
       "      <td>1243</td>\n",
       "      <td>104</td>\n",
       "      <td>267</td>\n",
       "      <td>976</td>\n",
       "      <td>30</td>\n",
       "      <td>0.780658</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.412</td>\n",
       "      <td>0.784</td>\n",
       "      <td>0.216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>299</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[0.33, 0.67]</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.5</td>\n",
       "      <td>Strict</td>\n",
       "      <td>41</td>\n",
       "      <td>88</td>\n",
       "      <td>26</td>\n",
       "      <td>34</td>\n",
       "      <td>54</td>\n",
       "      <td>15</td>\n",
       "      <td>0.623891</td>\n",
       "      <td>0.231</td>\n",
       "      <td>0.515</td>\n",
       "      <td>0.620</td>\n",
       "      <td>0.380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>299</td>\n",
       "      <td>[1, 0.67]</td>\n",
       "      <td>[0.33]</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.5</td>\n",
       "      <td>Strict</td>\n",
       "      <td>56</td>\n",
       "      <td>73</td>\n",
       "      <td>28</td>\n",
       "      <td>33</td>\n",
       "      <td>40</td>\n",
       "      <td>28</td>\n",
       "      <td>0.523973</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.479</td>\n",
       "      <td>0.527</td>\n",
       "      <td>0.473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>299</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[0.33]</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.5</td>\n",
       "      <td>Exhaustive</td>\n",
       "      <td>38</td>\n",
       "      <td>72</td>\n",
       "      <td>26</td>\n",
       "      <td>28</td>\n",
       "      <td>44</td>\n",
       "      <td>12</td>\n",
       "      <td>0.647661</td>\n",
       "      <td>0.281</td>\n",
       "      <td>0.565</td>\n",
       "      <td>0.636</td>\n",
       "      <td>0.364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>299</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[0.33, 0.67]</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.5</td>\n",
       "      <td>Exhaustive</td>\n",
       "      <td>41</td>\n",
       "      <td>88</td>\n",
       "      <td>23</td>\n",
       "      <td>25</td>\n",
       "      <td>63</td>\n",
       "      <td>18</td>\n",
       "      <td>0.638442</td>\n",
       "      <td>0.267</td>\n",
       "      <td>0.517</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>299</td>\n",
       "      <td>[1, 0.67]</td>\n",
       "      <td>[0.33]</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.5</td>\n",
       "      <td>Exhaustive</td>\n",
       "      <td>56</td>\n",
       "      <td>73</td>\n",
       "      <td>31</td>\n",
       "      <td>34</td>\n",
       "      <td>39</td>\n",
       "      <td>25</td>\n",
       "      <td>0.543909</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.512</td>\n",
       "      <td>0.543</td>\n",
       "      <td>0.457</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>720 rows Ã— 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Seed True_Var_Def False_Var_Def  VAF_Lower_Limit  VAF_Upper_Limit  \\\n",
       "0     10          [1]        [0.33]             0.01              0.6   \n",
       "0     10          [1]  [0.33, 0.67]             0.01              0.6   \n",
       "0     10    [1, 0.67]        [0.33]             0.01              0.6   \n",
       "0     10          [1]        [0.33]             0.01              0.6   \n",
       "0     10          [1]  [0.33, 0.67]             0.01              0.6   \n",
       "..   ...          ...           ...              ...              ...   \n",
       "0    299          [1]  [0.33, 0.67]             0.10              0.5   \n",
       "0    299    [1, 0.67]        [0.33]             0.10              0.5   \n",
       "0    299          [1]        [0.33]             0.10              0.5   \n",
       "0    299          [1]  [0.33, 0.67]             0.10              0.5   \n",
       "0    299    [1, 0.67]        [0.33]             0.10              0.5   \n",
       "\n",
       "   Feature_Category  Num_True_Var_Testing  Num_False_Var_Testing   TP   FP  \\\n",
       "0          Moderate                   159                   1055  123  230   \n",
       "0          Moderate                   134                   1243  104  253   \n",
       "0          Moderate                   287                   1090  187  310   \n",
       "0            Strict                   159                   1055  126  240   \n",
       "0            Strict                   134                   1243  104  267   \n",
       "..              ...                   ...                    ...  ...  ...   \n",
       "0            Strict                    41                     88   26   34   \n",
       "0            Strict                    56                     73   28   33   \n",
       "0        Exhaustive                    38                     72   26   28   \n",
       "0        Exhaustive                    41                     88   23   25   \n",
       "0        Exhaustive                    56                     73   31   34   \n",
       "\n",
       "     TN   FN       AUC    MCC  F1_score  Accuracy    MSE  \n",
       "0   825   36  0.777788  0.413     0.480     0.781  0.219  \n",
       "0   990   30  0.786290  0.387     0.424     0.794  0.206  \n",
       "0   780  100  0.683582  0.311     0.477     0.702  0.298  \n",
       "0   815   33  0.782482  0.415     0.480     0.775  0.225  \n",
       "0   976   30  0.780658  0.375     0.412     0.784  0.216  \n",
       "..  ...  ...       ...    ...       ...       ...    ...  \n",
       "0    54   15  0.623891  0.231     0.515     0.620  0.380  \n",
       "0    40   28  0.523973  0.048     0.479     0.527  0.473  \n",
       "0    44   12  0.647661  0.281     0.565     0.636  0.364  \n",
       "0    63   18  0.638442  0.267     0.517     0.667  0.333  \n",
       "0    39   25  0.543909  0.087     0.512     0.543  0.457  \n",
       "\n",
       "[720 rows x 17 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_snv_sbs = pd.read_csv(snv_sbs_file)\n",
    "df_perf_out_xgb = pd.DataFrame()\n",
    "\n",
    "# Use FDP coverage cutoff = 100 and remove low coverage samples and variants\n",
    "coverage_cutoff = 100\n",
    "df_snv_sbs = remove_low_coverage_samples(df_snv_sbs, coverage_cutoff, 'FDP')\n",
    "\n",
    "# Remove variants with FAO = 0\n",
    "fao_cutoff = 1\n",
    "df_snv_sbs = remove_low_coverage_samples(df_snv_sbs, fao_cutoff, 'FAO')\n",
    "\n",
    "# To eliminate the performance bias due to sampling, we will use a set of seeds to perform\n",
    "# random sampling. Using just a single seed might bias the testing data sampled\n",
    "# and a very good performance on just one testing dataset is highly indicative of\n",
    "# performance bias.\n",
    "seed_list = [10,20,3247,24,4501,9879,878,76,187,299]\n",
    "\n",
    "for seed_i in seed_list:\n",
    "    print (f\"Running predictions for all parameter/feature combinations with seed {seed_i}...\", end=\"\", flush=True)\n",
    "    df_perf_seed_i = pd.DataFrame()\n",
    "    for comb_i in param_combinations:\n",
    "        df_xgb_all_data = df_snv_sbs.copy()\n",
    "        af_lower_i, af_upper_i, feat_cat_i, true_var_i, false_var_i = comb_i\n",
    "        \n",
    "        # Commenting these print statements to reduce the amount of output text in the notebook\n",
    "        # Uncomment if you desire to see the combinations\n",
    "        #print (f\"Evaluating with parameters: af_lower_i={af_lower_i}, af_upper_i={af_upper_i}, feat_cat_i={feat_cat_i}, true_var_i={true_var_i}, false_var_i={false_var_i}\")\n",
    "    \n",
    "        # If the 2/3 variant is included in both the true variant and false variant\n",
    "        # then exclude that combination\n",
    "        if 0.67 in true_var_i and 0.67 in false_var_i:\n",
    "            continue\n",
    "        feature_cols = feat_cat_dict[feat_cat_i]\n",
    "        df_xgb_all_data = df_xgb_all_data.loc[(df_xgb_all_data['AF'] > af_lower_i) & \n",
    "                                             (df_xgb_all_data['AF'] < af_upper_i)]\n",
    "        if len(true_var_i) == 1 and len(false_var_i) == 1:\n",
    "            df_xgb_all_data = df_xgb_all_data.loc[(df_xgb_all_data['PERCENT_OVERLAP'] == true_var_i[0]) |\n",
    "                                                (df_xgb_all_data['PERCENT_OVERLAP'] == false_var_i[0])]\n",
    "\n",
    "        df_xgb_all_data.reset_index(drop=True, inplace=True)\n",
    "        if len(true_var_i) == 1:\n",
    "            overlap_cat = list(df_xgb_all_data['PERCENT_OVERLAP'].apply(lambda x: 1 if (x == true_var_i[0]) else 0 ))\n",
    "        else:\n",
    "            overlap_cat = list(df_xgb_all_data['PERCENT_OVERLAP'].apply(lambda x: 1 if (x == true_var_i[0] or x == true_var_i[1]) else 0 ))\n",
    "\n",
    "        df_xgb_all_data['OVERLAP_CATEGORY'] = overlap_cat\n",
    "        target_cols = 'OVERLAP_CATEGORY'\n",
    "\n",
    "        # Define X and y \n",
    "        X = df_xgb_all_data[feature_cols]\n",
    "        y = df_xgb_all_data[target_cols].tolist()\n",
    "\n",
    "        # Create balanced datasets\n",
    "        train_sample, X_test, y_test, train_index_list = create_balanced_datasets(X,y, seed_i)\n",
    "\n",
    "        # Train model\n",
    "        num_jobs = 6\n",
    "        n_trees = 100\n",
    "        mdepth = 10\n",
    "        xgb_model = XGBClassifier(use_label_encoder=False, \n",
    "                              booster='gbtree', # boosting algorithm to use, default gbtree, othera: gblinear, dart\n",
    "                              n_estimators=n_trees, # number of trees, default = 100\n",
    "                              eta=0.2, # this is learning rate, default = 0.3\n",
    "                              max_depth=mdepth, # maximum depth of the tree, default = 6\n",
    "                              gamma = 1, # used for pruning, if gain < gamma the branch will be pruned, default = 0\n",
    "                              reg_lambda = 1, # regularization parameter, defautl = 1\n",
    "                              eval_metric = 'logloss'\n",
    "                             )\n",
    "        fpr_tpr = [] # Store all the fpr, tpr values for each model \n",
    "        auc_scores = []\n",
    "        df_y_pred_all_models = pd.DataFrame()\n",
    "        df_y_scores_all_models = pd.DataFrame()\n",
    "        df_all_cv_scores = pd.DataFrame()\n",
    "        df_feature_importances_all_models = pd.DataFrame()\n",
    "        for model_i in list(train_sample.keys()):\n",
    "            X_train_model_i = train_sample[model_i]['X_train']\n",
    "            y_train_model_i = train_sample[model_i]['y_train']\n",
    "    #         print (f\"Running CV and predictions for model {model_i}...\", end='', flush=True)\n",
    "            X_train_model_i = X_train_model_i.apply(pd.to_numeric)\n",
    "            xgb_model.fit(X_train_model_i,y_train_model_i)\n",
    "\n",
    "            # Predict using model_i on the test data\n",
    "            y_pred = xgb_model.predict(X_test)\n",
    "            df_y_pred_all_models[f\"Model_{model_i}\"] = y_pred\n",
    "            y_test_pred_scores = xgb_model.predict_proba(X_test)[:, 1]\n",
    "            df_y_scores_all_models[f\"Model_{model_i}\"] = y_test_pred_scores\n",
    "            false_positive, true_positive, _ = roc_curve(y_test, y_test_pred_scores)\n",
    "            fpr_tpr.append([false_positive,true_positive])\n",
    "            auc_test = roc_auc_score(y_test, y_pred)\n",
    "            auc_scores.append(auc_test)\n",
    "        # Get the consensus predictions from all models\n",
    "        y_pred_consensus = get_ensemble_prediction(df_y_scores_all_models)\n",
    "\n",
    "        # Calculate metrics on the consensus prediction\n",
    "        auc_test = roc_auc_score(y_test, y_pred_consensus)\n",
    "\n",
    "        # Calculate the F1 score\n",
    "        F1_score_test = round(f1_score(y_test, y_pred_consensus), 3)\n",
    "\n",
    "        # Calculate the mean-squared error\n",
    "        mse_test = round(mean_squared_error(y_test, y_pred_consensus), 3)\n",
    "\n",
    "        # Calculate the accuracy\n",
    "        accuracy_test = round(accuracy_score(y_test, y_pred_consensus), 3)\n",
    "\n",
    "        # Calculate the MCC\n",
    "        mcc_test = round(matthews_corrcoef(y_test, y_pred_consensus), 3)\n",
    "\n",
    "        # Print the performance metrics on test data\n",
    "        # Uncomment to see the metrics for each combination\n",
    "        #print (\"AUC =\", round(auc_test, 3), \", F1 score =\", F1_score_test, \", Mean-squared error =\", mse_test, \", Accuracy =\", accuracy_test, \", Matthews correlation coefficient =\", mcc_test)\n",
    "\n",
    "        # Get the confusion matrix\n",
    "        cm = confusion_matrix(y_test, y_pred_consensus)\n",
    "\n",
    "        # Get the indices of false positives\n",
    "        false_positive_ind = list(set(np.where(np.array(y_test) == 0)[0]).intersection(set(np.where(np.array(y_pred_consensus) == 1)[0])))\n",
    "        # Get the indices of true positives\n",
    "        true_positive_ind = list(set(np.where(np.array(y_test) == 1)[0]).intersection(set(np.where(np.array(y_pred_consensus) == 1)[0])))\n",
    "        # Get the indices of true negatives\n",
    "        true_negative_ind = list(set(np.where(np.array(y_test) == 0)[0]).intersection(set(np.where(np.array(y_pred_consensus) == 0)[0])))\n",
    "        # Get the indices of false negatives\n",
    "        false_negative_ind = list(set(np.where(np.array(y_test) == 1)[0]).intersection(set(np.where(np.array(y_pred_consensus) == 0)[0])))\n",
    "\n",
    "        fp = len(false_positive_ind)\n",
    "        tp = len(true_positive_ind)\n",
    "        tn = len(true_negative_ind)\n",
    "        fn = len(false_negative_ind)\n",
    "\n",
    "        cols = ['Seed', 'True_Var_Def', 'False_Var_Def', 'VAF_Lower_Limit', 'VAF_Upper_Limit',  'Feature_Category',\n",
    "                'Num_True_Var_Testing', 'Num_False_Var_Testing', 'TP', 'FP', 'TN', 'FN', 'AUC', 'MCC', \n",
    "                'F1_score', 'Accuracy', 'MSE']\n",
    "\n",
    "        # Add an additional space before the true var def and false var def. Otherwise, excel formats it as date.\n",
    "        df_tmp = pd.DataFrame(data=[[seed_i, true_var_i, false_var_i,af_lower_i,af_upper_i,feat_cat_i, \n",
    "                                     tp+fn, tn+fp, tp, fp, tn, fn, auc_test, mcc_test, F1_score_test,\n",
    "                                     accuracy_test, mse_test]], columns=cols)\n",
    "        df_perf_seed_i = df_perf_seed_i.append(df_tmp)\n",
    "        #break\n",
    "    df_perf_out_xgb = df_perf_out_xgb.append(df_perf_seed_i)\n",
    "    print (\"Done!\")\n",
    "df_perf_out_xgb.to_csv(perf_out_file_xgb, index=False)\n",
    "df_perf_out_xgb "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d7be0e",
   "metadata": {},
   "source": [
    "## Performance with results from VCFgenie, but without a lower bound on VAF - <b> <font color='orange'> VM models </font> </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1000de2d",
   "metadata": {},
   "source": [
    "### Define input and output files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8a328a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The input vcf .csv file\n",
    "snv_sbs_file = '../data/SNV_data_with_vcf_genie.csv'\n",
    "perf_out_file_xgb = outdir + 'performance_VM.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f1d4ed",
   "metadata": {},
   "source": [
    "### Define parameters and conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ac66a82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "af_upper = [0.6,0.5]\n",
    "feature_cat = ['Moderate', 'Strict', 'Exhaustive']\n",
    "true_var = [[1],[1,0.67]]\n",
    "false_var = [[0.33], [0.33, 0.67]] # Skip if 0.67 is in both true_var and false_var\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fcf5e42",
   "metadata": {},
   "source": [
    "### Define features categories as a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ac0740ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_cat_dict = {'Moderate': ['FSAF','FSAR','FSRF','FSRR','FWDB','FXX','GQ','MLLD','QUAL','REFB',\n",
    "                'REVB','SAF','SAR','SRF','SRR','SSSB','STB','VARB', '5_PRIME_NUCLEOTIDE_CONTEXT', '3_PRIME_NUCLEOTIDE_CONTEXT'],\n",
    "                'Strict': ['FSAF','FSAR','FSRF','FSRR','FWDB','FXX','MLLD','QUAL','REFB','REVB','SSSB','VARB', \n",
    "                           '5_PRIME_NUCLEOTIDE_CONTEXT', '3_PRIME_NUCLEOTIDE_CONTEXT'],\n",
    "                'Exhaustive': ['AO','DP','FAO','FDP','FRO','FSAF','FSAR','FSRF','FSRR','FWDB',\n",
    "                'FXX','GQ','HRUN','LEN','MLLD','QD','QUAL','RBI','REFB','REVB',\n",
    "                'RO','SAF','SAR','SRF','SRR','SSSB','STB','STBP','VARB', '5_PRIME_NUCLEOTIDE_CONTEXT',\n",
    "                '3_PRIME_NUCLEOTIDE_CONTEXT']\n",
    "                }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5bfa8c",
   "metadata": {},
   "source": [
    "### Generate combinations of conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3c7886fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.6, 'Moderate', [1], [0.33]), (0.6, 'Moderate', [1], [0.33, 0.67]), (0.6, 'Moderate', [1, 0.67], [0.33]), (0.6, 'Moderate', [1, 0.67], [0.33, 0.67]), (0.6, 'Strict', [1], [0.33]), (0.6, 'Strict', [1], [0.33, 0.67]), (0.6, 'Strict', [1, 0.67], [0.33]), (0.6, 'Strict', [1, 0.67], [0.33, 0.67]), (0.6, 'Exhaustive', [1], [0.33]), (0.6, 'Exhaustive', [1], [0.33, 0.67]), (0.6, 'Exhaustive', [1, 0.67], [0.33]), (0.6, 'Exhaustive', [1, 0.67], [0.33, 0.67]), (0.5, 'Moderate', [1], [0.33]), (0.5, 'Moderate', [1], [0.33, 0.67]), (0.5, 'Moderate', [1, 0.67], [0.33]), (0.5, 'Moderate', [1, 0.67], [0.33, 0.67]), (0.5, 'Strict', [1], [0.33]), (0.5, 'Strict', [1], [0.33, 0.67]), (0.5, 'Strict', [1, 0.67], [0.33]), (0.5, 'Strict', [1, 0.67], [0.33, 0.67]), (0.5, 'Exhaustive', [1], [0.33]), (0.5, 'Exhaustive', [1], [0.33, 0.67]), (0.5, 'Exhaustive', [1, 0.67], [0.33]), (0.5, 'Exhaustive', [1, 0.67], [0.33, 0.67])]\n",
      "Total combinations = 24\n"
     ]
    }
   ],
   "source": [
    "param_combinations = list(product(af_upper, feature_cat, true_var, false_var))\n",
    "print (param_combinations)\n",
    "print (f\"Total combinations = {len(param_combinations)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8766a262",
   "metadata": {},
   "source": [
    "### Run Xtreme Gradient Boosting iteratively on these conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c1ffcc03",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing low FDP variants...Done!\n",
      "Removing low FAO variants...Done!\n",
      "***Running predictions for all parameter/feature combinations with seed 10***Done!\n",
      "***Running predictions for all parameter/feature combinations with seed 20***Done!\n",
      "***Running predictions for all parameter/feature combinations with seed 3247***Done!\n",
      "***Running predictions for all parameter/feature combinations with seed 24***Done!\n",
      "***Running predictions for all parameter/feature combinations with seed 4501***Done!\n",
      "***Running predictions for all parameter/feature combinations with seed 9879***Done!\n",
      "***Running predictions for all parameter/feature combinations with seed 878***Done!\n",
      "***Running predictions for all parameter/feature combinations with seed 76***Done!\n",
      "***Running predictions for all parameter/feature combinations with seed 187***Done!\n",
      "***Running predictions for all parameter/feature combinations with seed 299***Done!\n"
     ]
    }
   ],
   "source": [
    "df_snv_sbs = pd.read_csv(snv_sbs_file)\n",
    "df_perf_out_xgb = pd.DataFrame()\n",
    "\n",
    "# Use FDP coverage cutoff = 100 and remove low coverage samples and variants\n",
    "coverage_cutoff = 100\n",
    "print (\"Removing low FDP variants...\", end='', flush=True)\n",
    "df_snv_sbs = remove_low_coverage_samples(df_snv_sbs, coverage_cutoff, 'FDP')\n",
    "print (\"Done!\")\n",
    "\n",
    "# Remove variants with FAO = 0\n",
    "fao_cutoff = 1\n",
    "print (\"Removing low FAO variants...\", end='', flush=True)\n",
    "df_snv_sbs = remove_low_coverage_samples(df_snv_sbs, fao_cutoff, 'FAO')\n",
    "print (\"Done!\")\n",
    "\n",
    "seed_list = [10,20,3247,24,4501,9879,878,76,187,299]\n",
    "for seed_i in seed_list:\n",
    "    print (f\"Running predictions for all parameter/feature combinations with seed {seed_i}...\", end=\"\", flush=True)\n",
    "    df_perf_seed_i = pd.DataFrame()\n",
    "    for comb_i in param_combinations:\n",
    "        df_xgb_all_data = df_snv_sbs.copy()\n",
    "        af_upper_i, feat_cat_i, true_var_i, false_var_i = comb_i\n",
    "        #print (f\"Evaluating with parameters: af_upper_i={af_upper_i}, feat_cat_i={feat_cat_i}, true_var_i={true_var_i}, false_var_i={false_var_i}\")\n",
    "    #     print(af_lower_i, af_upper_i, feat_cat_i, true_var_i, false_var_i, exclude_lin_pos_i)\n",
    "\n",
    "        # If the 2/3 variant is included in both the true variant and false variant\n",
    "        # then exclude that combination\n",
    "        if 0.67 in true_var_i and 0.67 in false_var_i:\n",
    "            continue\n",
    "        feature_cols = feat_cat_dict[feat_cat_i]\n",
    "        df_xgb_all_data = df_xgb_all_data.loc[(df_xgb_all_data['AF'] < af_upper_i)]\n",
    "\n",
    "        if len(true_var_i) == 1 and len(false_var_i) == 1:\n",
    "            df_xgb_all_data = df_xgb_all_data.loc[(df_xgb_all_data['PERCENT_OVERLAP'] == true_var_i[0]) |\n",
    "                                                (df_xgb_all_data['PERCENT_OVERLAP'] == false_var_i[0])]\n",
    "\n",
    "        df_xgb_all_data.reset_index(drop=True, inplace=True)\n",
    "        if len(true_var_i) == 1:\n",
    "            overlap_cat = list(df_xgb_all_data['PERCENT_OVERLAP'].apply(lambda x: 1 if (x == true_var_i[0]) else 0 ))\n",
    "        else:\n",
    "            overlap_cat = list(df_xgb_all_data['PERCENT_OVERLAP'].apply(lambda x: 1 if (x == true_var_i[0] or x == true_var_i[1]) else 0 ))\n",
    "\n",
    "        df_xgb_all_data['OVERLAP_CATEGORY'] = overlap_cat\n",
    "        target_cols = 'OVERLAP_CATEGORY'\n",
    "\n",
    "        # Define X and y \n",
    "        X = df_xgb_all_data[feature_cols]\n",
    "        y = df_xgb_all_data[target_cols].tolist()\n",
    "\n",
    "        # Create balanced datasets\n",
    "        train_sample, X_test, y_test, train_index_list = create_balanced_datasets(X,y,seed_i)\n",
    "\n",
    "        # Train model\n",
    "        num_jobs = 6\n",
    "        n_trees = 100\n",
    "        mdepth = 10\n",
    "        xgb_model = XGBClassifier(use_label_encoder=False, \n",
    "                              booster='gbtree', # boosting algorithm to use, default gbtree, othera: gblinear, dart\n",
    "                              n_estimators=n_trees, # number of trees, default = 100\n",
    "                              eta=0.2, # this is learning rate, default = 0.3\n",
    "                              max_depth=mdepth, # maximum depth of the tree, default = 6\n",
    "                              gamma = 1, # used for pruning, if gain < gamma the branch will be pruned, default = 0\n",
    "                              reg_lambda = 1, # regularization parameter, defautl = 1\n",
    "                              eval_metric = 'logloss'\n",
    "                             )\n",
    "        fpr_tpr = [] # Store all the fpr, tpr values for each model \n",
    "        auc_scores = []\n",
    "        df_y_pred_all_models = pd.DataFrame()\n",
    "        df_y_scores_all_models = pd.DataFrame()\n",
    "        df_all_cv_scores = pd.DataFrame()\n",
    "        df_feature_importances_all_models = pd.DataFrame()\n",
    "        for model_i in list(train_sample.keys()):\n",
    "            X_train_model_i = train_sample[model_i]['X_train']\n",
    "            y_train_model_i = train_sample[model_i]['y_train']\n",
    "    #         print (f\"Running CV and predictions for model {model_i}...\", end='', flush=True)\n",
    "            X_train_model_i = X_train_model_i.apply(pd.to_numeric)\n",
    "            xgb_model.fit(X_train_model_i,y_train_model_i)\n",
    "\n",
    "            # Predict using model_i on the test data\n",
    "            y_pred = xgb_model.predict(X_test)\n",
    "            df_y_pred_all_models[f\"Model_{model_i}\"] = y_pred\n",
    "            y_test_pred_scores = xgb_model.predict_proba(X_test)[:, 1]\n",
    "            df_y_scores_all_models[f\"Model_{model_i}\"] = y_test_pred_scores\n",
    "            false_positive, true_positive, _ = roc_curve(y_test, y_test_pred_scores)\n",
    "            fpr_tpr.append([false_positive,true_positive])\n",
    "            auc_test = roc_auc_score(y_test, y_pred)\n",
    "            auc_scores.append(auc_test)\n",
    "        # Get the consensus predictions from all models\n",
    "        y_pred_consensus = get_ensemble_prediction(df_y_scores_all_models)\n",
    "\n",
    "        # Calculate metrics on the consensus prediction\n",
    "        auc_test = roc_auc_score(y_test, y_pred_consensus)\n",
    "\n",
    "        # Calculate the F1 score\n",
    "        F1_score_test = round(f1_score(y_test, y_pred_consensus), 3)\n",
    "\n",
    "        # Calculate the mean-squared error\n",
    "        mse_test = round(mean_squared_error(y_test, y_pred_consensus), 3)\n",
    "\n",
    "        # Calculate the accuracy\n",
    "        accuracy_test = round(accuracy_score(y_test, y_pred_consensus), 3)\n",
    "\n",
    "        # Calculate the MCC\n",
    "        mcc_test = round(matthews_corrcoef(y_test, y_pred_consensus), 3)\n",
    "\n",
    "        # Print the performance metrics on test data\n",
    "        #print (\"AUC =\", round(auc_test, 3), \", F1 score =\", F1_score_test, \", Mean-squared error =\", mse_test, \", Accuracy =\", accuracy_test, \", Matthews correlation coefficient =\", mcc_test)\n",
    "        \n",
    "        # Get the confusion matrix\n",
    "        cm = confusion_matrix(y_test, y_pred_consensus)\n",
    "\n",
    "        # Get the indices of false positives\n",
    "        false_positive_ind = list(set(np.where(np.array(y_test) == 0)[0]).intersection(set(np.where(np.array(y_pred_consensus) == 1)[0])))\n",
    "        # Get the indices of true positives\n",
    "        true_positive_ind = list(set(np.where(np.array(y_test) == 1)[0]).intersection(set(np.where(np.array(y_pred_consensus) == 1)[0])))\n",
    "        # Get the indices of true negatives\n",
    "        true_negative_ind = list(set(np.where(np.array(y_test) == 0)[0]).intersection(set(np.where(np.array(y_pred_consensus) == 0)[0])))\n",
    "        # Get the indices of false negatives\n",
    "        false_negative_ind = list(set(np.where(np.array(y_test) == 1)[0]).intersection(set(np.where(np.array(y_pred_consensus) == 0)[0])))\n",
    "\n",
    "        fp = len(false_positive_ind)\n",
    "        tp = len(true_positive_ind)\n",
    "        tn = len(true_negative_ind)\n",
    "        fn = len(false_negative_ind)\n",
    "\n",
    "        cols = ['Seed', 'True_Var_Def', 'False_Var_Def', 'VAF_Upper_Limit', 'Feature_Category', \n",
    "                'Num_True_Var_Testing', 'Num_False_Var_Testing', 'TP', 'FP', 'TN', 'FN', 'AUC', 'MCC', \n",
    "                'F1_score', 'Accuracy', 'MSE']\n",
    "\n",
    "        # Add an additional space before the true var def and false var def. Otherwise, excel formats it as date.\n",
    "        df_tmp = pd.DataFrame(data=[[seed_i, true_var_i, false_var_i,af_upper_i,feat_cat_i, tp+fn,\n",
    "                                     tn+fp, tp, fp, tn, fn, auc_test, mcc_test, F1_score_test,\n",
    "                                     accuracy_test, mse_test]], columns=cols)\n",
    "        df_perf_seed_i = df_perf_seed_i.append(df_tmp)\n",
    "\n",
    "        #break\n",
    "    df_perf_out_xgb =  df_perf_out_xgb.append(df_perf_seed_i)\n",
    "    print (\"Done!\")\n",
    "df_perf_out_xgb.to_csv(perf_out_file_xgb, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d090ec55",
   "metadata": {},
   "source": [
    "## Performance with results from VCFgenie and with a lower VAF and upper VAF cutoff - <b> <font color='royalblue'> FVM models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456e5e62",
   "metadata": {},
   "source": [
    "### Define input and output files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "68b5ff71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The input vcf .csv file\n",
    "\n",
    "snv_sbs_file = '../data/SNV_data_with_vcf_genie.csv'\n",
    "perf_out_file_xgb = outdir + 'performance_FVM.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdefaa50",
   "metadata": {},
   "source": [
    "### Define parameter and conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7b5f0439",
   "metadata": {},
   "outputs": [],
   "source": [
    "af_lower = [0.01,0.02,0.05,0.1]\n",
    "af_upper = [0.6,0.5]\n",
    "feature_cat = ['Moderate', 'Strict', 'Exhaustive']\n",
    "true_var = [[1],[1,0.67]]\n",
    "false_var = [[0.33], [0.33, 0.67]] # Skip if 0.67 is in both true_var and false_var"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7861b2b5",
   "metadata": {},
   "source": [
    "### Define feature categories as a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "41a76901",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_cat_dict = {'Moderate': ['FSAF','FSAR','FSRF','FSRR','FWDB','FXX','GQ','MLLD','QUAL','REFB',\n",
    "                'REVB','SAF','SAR','SRF','SRR','SSSB','STB','VARB', '5_PRIME_NUCLEOTIDE_CONTEXT', '3_PRIME_NUCLEOTIDE_CONTEXT'],\n",
    "                'Strict': ['FSAF','FSAR','FSRF','FSRR','FWDB','FXX','MLLD','QUAL','REFB','REVB','SSSB','VARB', \n",
    "                           '5_PRIME_NUCLEOTIDE_CONTEXT', '3_PRIME_NUCLEOTIDE_CONTEXT'],\n",
    "                'Exhaustive': ['AO','DP','FAO','FDP','FRO','FSAF','FSAR','FSRF','FSRR','FWDB',\n",
    "                'FXX','GQ','HRUN','LEN','MLLD','QD','QUAL','RBI','REFB','REVB',\n",
    "                'RO','SAF','SAR','SRF','SRR','SSSB','STB','STBP','VARB', '5_PRIME_NUCLEOTIDE_CONTEXT',\n",
    "                '3_PRIME_NUCLEOTIDE_CONTEXT']\n",
    "                }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35036649",
   "metadata": {},
   "source": [
    "### Generate combinations of conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e8901a9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.01, 0.6, 'Moderate', [1], [0.33]), (0.01, 0.6, 'Moderate', [1], [0.33, 0.67]), (0.01, 0.6, 'Moderate', [1, 0.67], [0.33]), (0.01, 0.6, 'Moderate', [1, 0.67], [0.33, 0.67]), (0.01, 0.6, 'Strict', [1], [0.33]), (0.01, 0.6, 'Strict', [1], [0.33, 0.67]), (0.01, 0.6, 'Strict', [1, 0.67], [0.33]), (0.01, 0.6, 'Strict', [1, 0.67], [0.33, 0.67]), (0.01, 0.6, 'Exhaustive', [1], [0.33]), (0.01, 0.6, 'Exhaustive', [1], [0.33, 0.67]), (0.01, 0.6, 'Exhaustive', [1, 0.67], [0.33]), (0.01, 0.6, 'Exhaustive', [1, 0.67], [0.33, 0.67]), (0.01, 0.5, 'Moderate', [1], [0.33]), (0.01, 0.5, 'Moderate', [1], [0.33, 0.67]), (0.01, 0.5, 'Moderate', [1, 0.67], [0.33]), (0.01, 0.5, 'Moderate', [1, 0.67], [0.33, 0.67]), (0.01, 0.5, 'Strict', [1], [0.33]), (0.01, 0.5, 'Strict', [1], [0.33, 0.67]), (0.01, 0.5, 'Strict', [1, 0.67], [0.33]), (0.01, 0.5, 'Strict', [1, 0.67], [0.33, 0.67]), (0.01, 0.5, 'Exhaustive', [1], [0.33]), (0.01, 0.5, 'Exhaustive', [1], [0.33, 0.67]), (0.01, 0.5, 'Exhaustive', [1, 0.67], [0.33]), (0.01, 0.5, 'Exhaustive', [1, 0.67], [0.33, 0.67]), (0.02, 0.6, 'Moderate', [1], [0.33]), (0.02, 0.6, 'Moderate', [1], [0.33, 0.67]), (0.02, 0.6, 'Moderate', [1, 0.67], [0.33]), (0.02, 0.6, 'Moderate', [1, 0.67], [0.33, 0.67]), (0.02, 0.6, 'Strict', [1], [0.33]), (0.02, 0.6, 'Strict', [1], [0.33, 0.67]), (0.02, 0.6, 'Strict', [1, 0.67], [0.33]), (0.02, 0.6, 'Strict', [1, 0.67], [0.33, 0.67]), (0.02, 0.6, 'Exhaustive', [1], [0.33]), (0.02, 0.6, 'Exhaustive', [1], [0.33, 0.67]), (0.02, 0.6, 'Exhaustive', [1, 0.67], [0.33]), (0.02, 0.6, 'Exhaustive', [1, 0.67], [0.33, 0.67]), (0.02, 0.5, 'Moderate', [1], [0.33]), (0.02, 0.5, 'Moderate', [1], [0.33, 0.67]), (0.02, 0.5, 'Moderate', [1, 0.67], [0.33]), (0.02, 0.5, 'Moderate', [1, 0.67], [0.33, 0.67]), (0.02, 0.5, 'Strict', [1], [0.33]), (0.02, 0.5, 'Strict', [1], [0.33, 0.67]), (0.02, 0.5, 'Strict', [1, 0.67], [0.33]), (0.02, 0.5, 'Strict', [1, 0.67], [0.33, 0.67]), (0.02, 0.5, 'Exhaustive', [1], [0.33]), (0.02, 0.5, 'Exhaustive', [1], [0.33, 0.67]), (0.02, 0.5, 'Exhaustive', [1, 0.67], [0.33]), (0.02, 0.5, 'Exhaustive', [1, 0.67], [0.33, 0.67]), (0.05, 0.6, 'Moderate', [1], [0.33]), (0.05, 0.6, 'Moderate', [1], [0.33, 0.67]), (0.05, 0.6, 'Moderate', [1, 0.67], [0.33]), (0.05, 0.6, 'Moderate', [1, 0.67], [0.33, 0.67]), (0.05, 0.6, 'Strict', [1], [0.33]), (0.05, 0.6, 'Strict', [1], [0.33, 0.67]), (0.05, 0.6, 'Strict', [1, 0.67], [0.33]), (0.05, 0.6, 'Strict', [1, 0.67], [0.33, 0.67]), (0.05, 0.6, 'Exhaustive', [1], [0.33]), (0.05, 0.6, 'Exhaustive', [1], [0.33, 0.67]), (0.05, 0.6, 'Exhaustive', [1, 0.67], [0.33]), (0.05, 0.6, 'Exhaustive', [1, 0.67], [0.33, 0.67]), (0.05, 0.5, 'Moderate', [1], [0.33]), (0.05, 0.5, 'Moderate', [1], [0.33, 0.67]), (0.05, 0.5, 'Moderate', [1, 0.67], [0.33]), (0.05, 0.5, 'Moderate', [1, 0.67], [0.33, 0.67]), (0.05, 0.5, 'Strict', [1], [0.33]), (0.05, 0.5, 'Strict', [1], [0.33, 0.67]), (0.05, 0.5, 'Strict', [1, 0.67], [0.33]), (0.05, 0.5, 'Strict', [1, 0.67], [0.33, 0.67]), (0.05, 0.5, 'Exhaustive', [1], [0.33]), (0.05, 0.5, 'Exhaustive', [1], [0.33, 0.67]), (0.05, 0.5, 'Exhaustive', [1, 0.67], [0.33]), (0.05, 0.5, 'Exhaustive', [1, 0.67], [0.33, 0.67]), (0.1, 0.6, 'Moderate', [1], [0.33]), (0.1, 0.6, 'Moderate', [1], [0.33, 0.67]), (0.1, 0.6, 'Moderate', [1, 0.67], [0.33]), (0.1, 0.6, 'Moderate', [1, 0.67], [0.33, 0.67]), (0.1, 0.6, 'Strict', [1], [0.33]), (0.1, 0.6, 'Strict', [1], [0.33, 0.67]), (0.1, 0.6, 'Strict', [1, 0.67], [0.33]), (0.1, 0.6, 'Strict', [1, 0.67], [0.33, 0.67]), (0.1, 0.6, 'Exhaustive', [1], [0.33]), (0.1, 0.6, 'Exhaustive', [1], [0.33, 0.67]), (0.1, 0.6, 'Exhaustive', [1, 0.67], [0.33]), (0.1, 0.6, 'Exhaustive', [1, 0.67], [0.33, 0.67]), (0.1, 0.5, 'Moderate', [1], [0.33]), (0.1, 0.5, 'Moderate', [1], [0.33, 0.67]), (0.1, 0.5, 'Moderate', [1, 0.67], [0.33]), (0.1, 0.5, 'Moderate', [1, 0.67], [0.33, 0.67]), (0.1, 0.5, 'Strict', [1], [0.33]), (0.1, 0.5, 'Strict', [1], [0.33, 0.67]), (0.1, 0.5, 'Strict', [1, 0.67], [0.33]), (0.1, 0.5, 'Strict', [1, 0.67], [0.33, 0.67]), (0.1, 0.5, 'Exhaustive', [1], [0.33]), (0.1, 0.5, 'Exhaustive', [1], [0.33, 0.67]), (0.1, 0.5, 'Exhaustive', [1, 0.67], [0.33]), (0.1, 0.5, 'Exhaustive', [1, 0.67], [0.33, 0.67])]\n",
      "Total combinations = 96\n"
     ]
    }
   ],
   "source": [
    "param_combinations = list(product(af_lower, af_upper, feature_cat, true_var, false_var))\n",
    "print (param_combinations)\n",
    "print (f\"Total combinations = {len(param_combinations)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de992e60",
   "metadata": {},
   "source": [
    "### Run Xtreme Gradient Boosting iteratively in these conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "270f5b56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing low FDP variants...Done!\n",
      "Removing low FAO variants...Done!\n",
      "Running predictions for all parameter/feature combinations with seed 10...Done!\n",
      "Running predictions for all parameter/feature combinations with seed 20...Done!\n",
      "Running predictions for all parameter/feature combinations with seed 3247...Done!\n",
      "Running predictions for all parameter/feature combinations with seed 24...Done!\n",
      "Running predictions for all parameter/feature combinations with seed 4501...Done!\n",
      "Running predictions for all parameter/feature combinations with seed 9879...Done!\n",
      "Running predictions for all parameter/feature combinations with seed 878...Done!\n",
      "Running predictions for all parameter/feature combinations with seed 76...Done!\n",
      "Running predictions for all parameter/feature combinations with seed 187...Done!\n",
      "Running predictions for all parameter/feature combinations with seed 299...Done!\n"
     ]
    }
   ],
   "source": [
    "df_snv_sbs = pd.read_csv(snv_sbs_file)\n",
    "df_perf_out_xgb = pd.DataFrame()\n",
    "\n",
    "# Use FDP coverage cutoff = 100 and remove low coverage samples and variants\n",
    "coverage_cutoff = 100\n",
    "print (\"Removing low FDP variants...\", end='', flush=True)\n",
    "df_snv_sbs = remove_low_coverage_samples(df_snv_sbs, coverage_cutoff, 'FDP')\n",
    "print (\"Done!\")\n",
    "\n",
    "# Remove variants with FAO = 0\n",
    "fao_cutoff = 1\n",
    "print (\"Removing low FAO variants...\", end='', flush=True)\n",
    "df_snv_sbs = remove_low_coverage_samples(df_snv_sbs, fao_cutoff, 'FAO')\n",
    "print (\"Done!\")\n",
    "\n",
    "seed_list = [10,20,3247,24,4501,9879,878,76,187,299]\n",
    "for seed_i in seed_list:\n",
    "    print (f\"Running predictions for all parameter/feature combinations with seed {seed_i}...\", end=\"\", flush=True)\n",
    "    df_perf_seed_i = pd.DataFrame()\n",
    "    for comb_i in param_combinations:\n",
    "        df_xgb_all_data = df_snv_sbs.copy()\n",
    "        af_lower_i, af_upper_i, feat_cat_i, true_var_i, false_var_i = comb_i\n",
    "        #print (f\"Evaluating with parameters:\\n af_lower_i={af_lower_i}, af_upper_i={af_upper_i}, feat_cat_i={feat_cat_i}, true_var_i={true_var_i}, false_var_i={false_var_i}\")\n",
    "    #     print(af_lower_i, af_upper_i, feat_cat_i, true_var_i, false_var_i, exclude_lin_pos_i)\n",
    "\n",
    "        # If the 2/3 variant is included in both the true variant and false variant\n",
    "        # then exclude that combination\n",
    "        if 0.67 in true_var_i and 0.67 in false_var_i:\n",
    "            continue\n",
    "        feature_cols = feat_cat_dict[feat_cat_i]\n",
    "        df_xgb_all_data = df_xgb_all_data.loc[(df_xgb_all_data['AF'] > af_lower_i) & \n",
    "                                                (df_xgb_all_data['AF'] < af_upper_i)]\n",
    "        if len(true_var_i) == 1 and len(false_var_i) == 1:\n",
    "            df_xgb_all_data = df_xgb_all_data.loc[(df_xgb_all_data['PERCENT_OVERLAP'] == true_var_i[0]) |\n",
    "                                                (df_xgb_all_data['PERCENT_OVERLAP'] == false_var_i[0])]\n",
    "\n",
    "        df_xgb_all_data.reset_index(drop=True, inplace=True)\n",
    "        if len(true_var_i) == 1:\n",
    "            overlap_cat = list(df_xgb_all_data['PERCENT_OVERLAP'].apply(lambda x: 1 if (x == true_var_i[0]) else 0 ))\n",
    "        else:\n",
    "            overlap_cat = list(df_xgb_all_data['PERCENT_OVERLAP'].apply(lambda x: 1 if (x == true_var_i[0] or x == true_var_i[1]) else 0 ))\n",
    "\n",
    "        df_xgb_all_data['OVERLAP_CATEGORY'] = overlap_cat\n",
    "        target_cols = 'OVERLAP_CATEGORY'\n",
    "\n",
    "        # Define X and y \n",
    "        X = df_xgb_all_data[feature_cols]\n",
    "        y = df_xgb_all_data[target_cols].tolist()\n",
    "\n",
    "        # Create balanced datasets\n",
    "        train_sample, X_test, y_test, train_index_list = create_balanced_datasets(X,y,seed_i)\n",
    "\n",
    "        # Train model\n",
    "        num_jobs = 6\n",
    "        n_trees = 100\n",
    "        mdepth = 10\n",
    "        xgb_model = XGBClassifier(use_label_encoder=False, \n",
    "                              booster='gbtree', # boosting algorithm to use, default gbtree, othera: gblinear, dart\n",
    "                              n_estimators=n_trees, # number of trees, default = 100\n",
    "                              eta=0.2, # this is learning rate, default = 0.3\n",
    "                              max_depth=mdepth, # maximum depth of the tree, default = 6\n",
    "                              gamma = 1, # used for pruning, if gain < gamma the branch will be pruned, default = 0\n",
    "                              reg_lambda = 1, # regularization parameter, defautl = 1\n",
    "                              eval_metric = 'logloss'\n",
    "                             )\n",
    "        fpr_tpr = [] # Store all the fpr, tpr values for each model \n",
    "        auc_scores = []\n",
    "        df_y_pred_all_models = pd.DataFrame()\n",
    "        df_y_scores_all_models = pd.DataFrame()\n",
    "        df_all_cv_scores = pd.DataFrame()\n",
    "        df_feature_importances_all_models = pd.DataFrame()\n",
    "        for model_i in list(train_sample.keys()):\n",
    "            X_train_model_i = train_sample[model_i]['X_train']\n",
    "            y_train_model_i = train_sample[model_i]['y_train']\n",
    "    #         print (f\"Running CV and predictions for model {model_i}...\", end='', flush=True)\n",
    "            X_train_model_i = X_train_model_i.apply(pd.to_numeric)\n",
    "            xgb_model.fit(X_train_model_i,y_train_model_i)\n",
    "\n",
    "            # Predict using model_i on the test data\n",
    "            y_pred = xgb_model.predict(X_test)\n",
    "            df_y_pred_all_models[f\"Model_{model_i}\"] = y_pred\n",
    "            y_test_pred_scores = xgb_model.predict_proba(X_test)[:, 1]\n",
    "            df_y_scores_all_models[f\"Model_{model_i}\"] = y_test_pred_scores\n",
    "            false_positive, true_positive, _ = roc_curve(y_test, y_test_pred_scores)\n",
    "            fpr_tpr.append([false_positive,true_positive])\n",
    "            auc_test = roc_auc_score(y_test, y_pred)\n",
    "            auc_scores.append(auc_test)\n",
    "        # Get the consensus predictions from all models\n",
    "        y_pred_consensus = get_ensemble_prediction(df_y_scores_all_models)\n",
    "\n",
    "        # Calculate metrics on the consensus prediction\n",
    "        auc_test = roc_auc_score(y_test, y_pred_consensus)\n",
    "\n",
    "        # Calculate the F1 score\n",
    "        F1_score_test = round(f1_score(y_test, y_pred_consensus), 3)\n",
    "\n",
    "        # Calculate the mean-squared error\n",
    "        mse_test = round(mean_squared_error(y_test, y_pred_consensus), 3)\n",
    "\n",
    "        # Calculate the accuracy\n",
    "        accuracy_test = round(accuracy_score(y_test, y_pred_consensus), 3)\n",
    "\n",
    "        # Calculate the MCC\n",
    "        mcc_test = round(matthews_corrcoef(y_test, y_pred_consensus), 3)\n",
    "\n",
    "        # Print the performance metrics on test data\n",
    "        # print (\"\\tAUC =\", round(auc_test, 3), \"\\n\\tF1 score =\", F1_score_test, \"\\n\\tMean-squared error =\", mse_test, \"\\n\\tAccuracy =\", accuracy_test, \"\\n\\tMatthews correlation coefficient =\", mcc_test)\n",
    "\n",
    "        # Get the confusion matrix\n",
    "        cm = confusion_matrix(y_test, y_pred_consensus)\n",
    "\n",
    "        # Get the indices of false positives\n",
    "        false_positive_ind = list(set(np.where(np.array(y_test) == 0)[0]).intersection(set(np.where(np.array(y_pred_consensus) == 1)[0])))\n",
    "        # Get the indices of true positives\n",
    "        true_positive_ind = list(set(np.where(np.array(y_test) == 1)[0]).intersection(set(np.where(np.array(y_pred_consensus) == 1)[0])))\n",
    "        # Get the indices of true negatives\n",
    "        true_negative_ind = list(set(np.where(np.array(y_test) == 0)[0]).intersection(set(np.where(np.array(y_pred_consensus) == 0)[0])))\n",
    "        # Get the indices of false negatives\n",
    "        false_negative_ind = list(set(np.where(np.array(y_test) == 1)[0]).intersection(set(np.where(np.array(y_pred_consensus) == 0)[0])))\n",
    "\n",
    "        fp = len(false_positive_ind)\n",
    "        tp = len(true_positive_ind)\n",
    "        tn = len(true_negative_ind)\n",
    "        fn = len(false_negative_ind)\n",
    "\n",
    "        cols = ['Seed','True_Var_Def', 'False_Var_Def', 'VAF_Lower_Limit', 'VAF_Upper_Limit', 'Feature_Category', \n",
    "                'Num_True_Var_Testing', 'Num_False_Var_Testing', 'TP', 'FP', 'TN', 'FN', 'AUC', 'MCC', \n",
    "                'F1_score', 'Accuracy', 'MSE']\n",
    "\n",
    "        # Add an additional space before the true var def and false var def. Otherwise, excel formats it as date.\n",
    "        df_tmp = pd.DataFrame(data=[[seed_i, true_var_i, false_var_i,af_lower_i,af_upper_i,feat_cat_i, \n",
    "                                     tp+fn, tn+fp, tp, fp, tn, fn, auc_test, mcc_test, F1_score_test,\n",
    "                                     accuracy_test, mse_test]], columns=cols)\n",
    "        df_perf_seed_i = df_perf_seed_i.append(df_tmp)\n",
    "    df_perf_out_xgb = df_perf_out_xgb.append(df_perf_seed_i)\n",
    "    print (\"Done!\")\n",
    "df_perf_out_xgb.to_csv(perf_out_file_xgb, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d878d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5e20f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "294.398px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
